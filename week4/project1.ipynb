{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data 620 - Project 1\n",
    "\n",
    "Baron Curtin, Heither Geiger"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "\n",
    "For this project, we will be using data containing the networks of 10 different Facebook users (aka the \"ego nodes\"). This data will be downloaded from the Stanford Large Network Dataset Collection. The dataset is available here: https://snap.stanford.edu/data/ego-Facebook.html.\n",
    "\n",
    "Here, each node ID represents a Facebook user.\n",
    "\n",
    "For each of the 10 different networks (denoted by the ID of the user at the center of the network), we have the following files:\n",
    "\n",
    "\\*.edges - Each line will have two columns. The node IDs in column 1 and column 2 are connected to each other and to the ego node.\n",
    "\n",
    "\\*.circles - Each line will have an ID column (i.e. circle0, circle1, and so on), followed by anywhere from one to 100+ additional columns. The circles represent groups of users. Each node ID in every field of every line is connected to the ego node.\n",
    "\n",
    "\\*.featnames - Gives more info about which feature corresponds to each feature column. For example, \"8 education;classes;id;anonymized feature 8\" means that column 9 of the features file (with 0-based indexing) corresponds to an anonymized feature related to education (specifically, classes taken). \n",
    "\n",
    "\\*.egofeat and \\*.feat - For each feature explained in featnames, give whether the feature is true or false in each user for the ego node and all other nodes respectively."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "\n",
    "# additional jupyter setup\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "\n",
    "# create a constant for debugging to reduce size of graph\n",
    "DEBUG = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading/Parsing\n",
    "\n",
    "In the following code cells, we will be loading the data into Python and preparing it to be visualized with NetworkX\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "fb_path = Path('../week3/facebook')\n",
    "file_types = ('circles', 'edges', 'egofeat', 'feat', 'featnames')\n",
    "\n",
    "# load all files into python dictionary by file type\n",
    "# tuple in format (int(node), file_path)\n",
    "files = {file_type: [(int(f.stem), f) for f in fb_path.glob(f'*.{file_type}')] \n",
    "         for file_type in file_types}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that all of the files are loaded, we need to create a function that will parse each file appropriately\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### File Parsing Functions\n",
    "The below functions are helper functions that will be called in the main function parse_file(). \n",
    "Each of them are specific to a single type of file and the idiosyncracies that go along with that file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def circles_parser(lines='', **kwargs):\n",
    "    # circles files are tab delimited\n",
    "    info = [(int(kwargs['node']), int(n))\n",
    "            for l in lines \n",
    "            for n in l.split('\\t')[1:]\n",
    "            if l != '']\n",
    "    return info\n",
    "\n",
    "def edges_parser(lines='', **kwargs):\n",
    "    # edges files are separated by spaces\n",
    "    info = [x for l in lines\n",
    "            for x in combinations([*l.split(' '), kwargs['node']], 2)\n",
    "            if l != '']\n",
    "    return info\n",
    "\n",
    "def egofeat_parser(lines='', **kwargs):\n",
    "    # egofeat is separated by spaces\n",
    "    info = [x for l in lines\n",
    "            for x in l.split(' ')\n",
    "            if l != '']\n",
    "    return info\n",
    "\n",
    "def feat_parser(lines='', **kwargs):\n",
    "    # feat files are separated by spaces\n",
    "    info = [l.split(' ') \n",
    "            for l in lines\n",
    "            if l != '']\n",
    "    return info\n",
    "\n",
    "def featnames_parser(lines='', **kwargs):\n",
    "    # featnames files are delimited by ;\n",
    "    # we will only use the first index and the last index of the featurename\n",
    "    # as there are inconsistencies in length\n",
    "    info = [(l.split(';')[0], l.split(';')[-1])\n",
    "            for l in lines\n",
    "            if l != '']\n",
    "    return info\n",
    "\n",
    "\n",
    "# dictionary of file parsing functions for easy referencing later\n",
    "# using a dictionary will serve as a 'case' function\n",
    "file_parsers = {\n",
    "    'circles': circles_parser,\n",
    "    'edges': edges_parser,\n",
    "    'egofeat': egofeat_parser,\n",
    "    'feat': feat_parser,\n",
    "    'featnames': featnames_parser\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def parse_file(file_, node, file_type=''):\n",
    "    # basic error handling to make sure all required arguments are passed\n",
    "    if (file_ is None) | (node == '') | (file_type == ''):\n",
    "        raise ValueError('Unable to parse file without the required information')\n",
    "    \n",
    "    # get contents of the file\n",
    "    content = file_.read_text()\n",
    "    lines = content.split('\\n')\n",
    "    \n",
    "    # reduce size of lines base on debug\n",
    "    if DEBUG & (file_type in ['circles', 'edges']):\n",
    "        lines = lines[:20] if len(lines) > 20 else lines\n",
    "    \n",
    "    # parse based on file type\n",
    "    info = file_parsers[file_type](lines, node=node)\n",
    "    return info"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# we can use our created functions to create a new dictionary of parsed files\n",
    "parsed_files = {file_type: {node: parse_file(file_path, node, file_type)\n",
    "                            for node, file_path in list_of_nodes_files}\n",
    "                for file_type, list_of_nodes_files in files.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parsing the Categorical Feature (Gender)\n",
    "\n",
    "Each \"ego node\" has a file with a \".feat\" extension. The \".featnames\" file maps the columns in the \".feat\" file with the column name.\n",
    "We will only take the columns given a distinction for gender from each \".feat\" file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# gather all the feature (column) names by node\n",
    "feature_names = {int(node): ['_'.join(c) for c in cols]\n",
    "                 for node, cols in parsed_files['featnames'].items()}\n",
    "\n",
    "# create pandas dataframes for all nodes and relevant metrics\n",
    "feature_dfs = {node: pd.DataFrame(data=data, columns=['node', *feature_names[node]])\n",
    "               for node, data in parsed_files['feat'].items()}\n",
    "\n",
    "# remove unnecessary columns (keep gender columns)\n",
    "feature_dfs = {node: df.loc[:, ['node', *[col for col in df.columns\n",
    "                                if 'gender' in col]]]\n",
    "               for node, df in feature_dfs.items()}\n",
    "\n",
    "# create gender1 and gender2 classification\n",
    "for node, df in feature_dfs.items():\n",
    "    # get first column that matches feature 78\n",
    "    gender_col = next(col for col in df.columns if 'feature 78' in col)\n",
    "    \n",
    "    # use np.select for column creation\n",
    "    conditions = [df[gender_col].astype('int32') == 0, df[gender_col].astype('int32') == 1]\n",
    "    choices = ['gender1', 'gender2']\n",
    "    df['gender_class'] = np.select(conditions, choices, default='null')\n",
    "    \n",
    "    # set attributes in node: gender_class form\n",
    "    df['node'] = df['node'].astype('int32')\n",
    "    feature_dfs[node] = df.set_index('node')['gender_class'].to_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Graph Construction\n",
    "In the follow cells, we will be construct the network graph, adding edges, and adding the attributes.\n",
    "Adding the attributes will allow us to easily extract that information from the .Nodes method of NetworkX and put \n",
    "that information into a Pandas dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "\n",
    "# add edges from all the edges files\n",
    "g.add_edges_from([y for x in parsed_files['circles'].values()\n",
    "                  for y in x])\n",
    "\n",
    "# add edges from all the circles files\n",
    "g.add_edges_from([y for x in parsed_files['edges'].values()\n",
    "                  for y in x])\n",
    "\n",
    "# set node attributes\n",
    "for features in feature_dfs.values():\n",
    "    nx.set_node_attributes(g, features, 'gender')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# preliminary color, size, pos setup for graph\n",
    "pos = nx.spring_layout(g)\n",
    "bet_centrality = nx.betweenness_centrality(g, normalized=True, endpoints=True)\n",
    "node_color = [10000.0 * g.degree(v) for v in g]\n",
    "node_size = [v * 10000.0 for v in bet_centrality.values()]\n",
    "\n",
    "plt.figure(figsize=(50,20))\n",
    "nx.draw_networkx(g, pos=pos, node_color=node_color, node_size=node_size)\n",
    "plt.axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Network Analysis\n",
    "\n",
    "In the following cells we will calculate the degree centrality and eigenvector centrality and compare the centrality measures across nodes\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataframe Creation\n",
    "\n",
    "First we will calculate the centrality measures and the pass them, along with the gender information to the Pandas dataframe constructor.\n",
    "This will allow for easier data analysis afterwards as we can easily manipulate across nodes and categorical variables.\n",
    "The hard part with this dataset is that so many of the attributes are anonymized."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate degree centrality and eigenvector ventrality\n",
    "degree_centrality = nx.degree_centrality(g)\n",
    "eigen_centrality = nx.eigenvector_centrality(g)\n",
    "\n",
    "# assign attributes to the nodes\n",
    "nx.set_node_attributes(g, degree_centrality, 'degree_centrality')\n",
    "nx.set_node_attributes(g, eigen_centrality, 'eigenvector_centrality')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert graph data from nodes to a list of dictionaries to pass to pandas constructor\n",
    "graph_data = [{**{'node': node}, **data}\n",
    "              for node, data in g.nodes(data=True)]\n",
    "graph_df = pd.DataFrame(graph_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Centrality Analysis\n",
    "In the following section, we will be looking at the various centrality measures across the categorical groups.\n",
    "Putting the values in a dataframe will allow for easy data manipulation for these purposes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}